# AI Agent: Twitter Space Scraper, Dubber, and Poster

## 1. Overview

This document specifies the requirements for a Node.js TypeScript AI agent designed to:
1.  Scrape top Twitter profiles from SpacesDashboard.
2.  Identify recent recorded Twitter Spaces for those profiles.
3.  Extract the audio stream URL (`.m3u8`) for these Spaces.
4.  Download and host the audio publicly (AWS S3).
5.  Submit the audio to the SpeechLab API for dubbing into Latin American Spanish (`es_la`).
6.  Retrieve a sharing link for the completed SpeechLab project.
7.  Post this sharing link as a reply to the original Twitter Space tweet.

## Workflow Overview

This project consists of two main parts:

1.  **Python Scraper Utility (`scraper_utility/`):** Uses the `nova-act` library (AI-driven browser automation) to scrape the SpacesDashboard leaderboard. It extracts structured data (Space Title, Host Profile URL, Direct Space URL) for each entry and saves it to `leaderboard_data.json` in the project root.
2.  **Node.js Dubbing Agent (`src/`):** Reads the `leaderboard_data.json` file generated by the Python utility. For each entry in the file, it performs the dubbing workflow (Phases 2-6): finds the specific tweet (if needed, or uses the direct space URL), downloads/uploads audio, submits to SpeechLab, gets the sharing link, and posts the link back to Twitter.

## 2. Functional Requirements

### Phase 1: Scrape Leaderboard Data (Python Utility - `scraper_utility/scrape_leaderboard.py`)

*   **Goal:** Extract structured data for leaderboard entries and save to a file.
*   **Tool:** Python script using `nova-act` library.
*   **Input:** SpacesDashboard Leaderboard URL (`https://spacesdashboard.com/leaderboard?lang=en&mode=7d`). Requires `NOVA_ACT_API_KEY` environment variable.
*   **Method:**
    *   Launch `nova-act` targeting the leaderboard URL.
    *   Use natural language prompts (e.g., `nova.act(...)`) instructing the AI to:
        *   Identify distinct leaderboard entries.
        *   Extract `spaceTitle`, `hostProfileUrl` (converted from `/u/...`), and `directSpaceUrl` (from PLAY button link).
        *   Handle potential scrolling to load more entries.
    *   Provide a Pydantic schema (`LeaderboardEntry`) to guide data extraction.
    *   Deduplicate entries (e.g., based on `directSpaceUrl`).
    *   Limit the number of entries collected if desired.
*   **Output:** Creates/overwrites `leaderboard_data.json` in the project root, containing an array of `LeaderboardEntry` objects:
    ```json
    [
      {
        "spaceTitle": "Example Space Title",
        "hostProfileUrl": "https://x.com/exampleHost",
        "directSpaceUrl": "https://x.com/i/spaces/12345example"
      },
      // ... more entries
    ]
    ```
*   **Execution:** Run manually via `python scraper_utility/scrape_leaderboard.py` after setting up the Python environment and API key.

### Phase 2: Find Recorded Space & Extract Audio URL (Node.js Agent)

*   **Goal:** Extract the `.m3u8` audio stream URL for a given recorded Twitter Space.
*   **Input:** A `LeaderboardEntry` object (read from `leaderboard_data.json`), specifically the `directSpaceUrl` or potentially the `hostProfileUrl`.
*   **Method:**
    *   Use Playwright (`src/services/twitterInteractionService.ts`).
    *   Navigate either directly to the `directSpaceUrl` **or** to the `hostProfileUrl` to find the relevant tweet/space card.
    *   Identify the element indicating a recorded space (e.g., "Play recording" button).
    *   Simulate clicking the "Play recording" button.
    *   Intercept network requests to capture the `*.pscp.tv/.../playlist_*.m3u8` URL.
*   **Output:** The `.m3u8` URL (string) or `null`.
*   **Logging:** `[üê¶ Twitter]` ...

### Phase 3: Download, Convert, and Host Audio

*   **Goal:** Download audio from the `.m3u8` URL and upload it to a public AWS S3 bucket.
*   **Method:**
    *   Use `ffmpeg` (via command line execution or `fluent-ffmpeg`).
    *   Execute `ffmpeg` command to download and save the stream as a single file (e.g., `.aac` or `.mp3`).
        ```bash
        # Example ffmpeg command
        ffmpeg -protocol_whitelist file,http,https,tcp,tls,crypto -i "M3U8_URL" -c copy output_audio.aac
        ```
    *   Use the AWS SDK for JavaScript v3 (`@aws-sdk/client-s3`).
    *   Configure SDK using standard AWS environment variables (e.g., `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`).
    *   Upload the downloaded audio file to the `speechlab-test-files-public` S3 bucket.
    *   Ensure the uploaded object has `public-read` ACL.
    *   Construct the public S3 URL (e.g., `https://speechlab-test-files-public.s3.amazonaws.com/YOUR_UPLOADED_FILENAME`).
*   **Input:** The `.m3u8` URL.
*   **Output:** The public URL of the hosted audio file.
*   **Logging:** `[üéß Audio]` Log `.m3u8` processing start, `ffmpeg` command/status, download start/end, upload start/end, public S3 URL, errors.

### Phase 4: Dub Audio using SpeechLab API

*   **Goal:** Submit the hosted audio file to the SpeechLab API for dubbing.
*   **Method:**
    *   **Authentication:**
        *   Create `getSpeechLabToken()` function.
        *   Read `SPEECHLAB_EMAIL`, `SPEECHLAB_PASSWORD` from `.env`.
        *   `POST /v1/auth/login` to `https://translate-api.speechlab.ai`.
        *   Extract and return JWT `accessToken`. Implement caching/reuse.
    *   **Dub Creation:**
        *   Obtain token.
        *   Construct payload for `POST /v1/projects/createProjectAndDub`:
            *   `name`: Use extracted Space Name (or a default like "Dubbed Space [Timestamp]").
            *   `sourceLanguage`: `"en"`.
            *   `targetLanguage`: `"es_la"`.
            *   `dubAccent`: `"es_la"`.
            *   `unitType`: `"whiteGlove"`.
            *   `mediaFileURI`: The public S3 URL from Phase 3.
            *   `voiceMatchingMode`: `"source"`.
            *   `thirdPartyID`: Use extracted Space Name (or a default).
            *   `customizedVoiceMatchingSpeakers`: `[]` (or the example structure if needed later, confirm necessity).
        *   Make the POST request with `Authorization: Bearer <token>`.
        *   Parse response, extract and store `projectId`.
*   **Input:** Public S3 URL, Space Name.
*   **Output:** SpeechLab `projectId`.
*   **Logging:** `[ü§ñ SpeechLab]` Log "Submitting dub request", API payload (mask token), API response status, `projectId`, errors.

### Phase 5: Get SpeechLab Sharing Link

*   **Goal:** Obtain the public sharing link for the completed dubbing project.
*   **Method:**
    *   Obtain token.
    *   Make a `POST /v1/collaborations/generateSharingLink` request to `https://translate-api.speechlab.ai`.
    *   Request Body: `{"projectId": "PROJECT_ID_FROM_PHASE_4"}`
    *   Headers: `Authorization: Bearer <token>`, `Content-Type: application/json`.
    *   Parse the JSON response, extract the value from the `link` field.
*   **Input:** SpeechLab `projectId`.
*   **Output:** Sharing link URL string.
*   **Logging:** `[üîó SpeechLab]` Log "Fetching sharing link", `projectId`, API response status, extracted link, errors.

### Phase 6: Post Comment to Twitter

*   **Goal:** Post the SpeechLab sharing link as a reply to the original Twitter Space tweet.
*   **Method:**
    *   Use the same `Puppeteer`/`Playwright` instance/session.
    *   Navigate back to or ensure focus on the original tweet URL identified in Phase 2.
    *   Locate the "Reply" button/input field for that specific tweet.
    *   Construct the comment text: `"Speechlab Twitter Space Agent sponsored by @shaftfinance $shaft has dubbed this space in Latin Spanish!! <LINK>?"` replacing `<LINK>` with the URL from Phase 5.
    *   Simulate typing the comment and clicking the "Post" or "Reply" button.
*   **Input:** Original Tweet URL, SpeechLab Sharing Link.
*   **Output:** Comment posted on Twitter.
*   **Logging:** `[üê¶ Twitter]` Log "Posting reply to", tweet URL, comment text, post success/failure status, errors.

## 3. Agent Orchestration (Node.js Agent - `src/agents/TwitterSpaceDubbingAgent.ts`)

1.  **Initialization:** Agent starts.
2.  **Load Leaderboard Data:**
    *   Read and parse `leaderboard_data.json` from the project root.
    *   Log the number of entries loaded.
    *   Handle errors if the file doesn't exist or is invalid (instruct user to run Python scraper).
3.  **Iterate Entries:** Loop through the loaded array of `LeaderboardEntry` objects.
    *   For each `entry`:
        *   Log processing start for the entry (e.g., using `spaceTitle` or `directSpaceUrl`).
        *   **Execute Workflow (Phases 2-6):**
            *   Call `twitterInteractionService.findM3u8ForSpace(entry.directSpaceUrl)` (New function needed or adapt existing).
            *   Call `audioService.downloadAndUploadAudio(m3u8Url, entry.spaceTitle)`. (Phase 3)
            *   Call `speechlabApiService.createDubbingProject(publicAudioUrl, entry.spaceTitle)`. (Phase 4)
            *   Call `speechlabApiService.generateSharingLink(projectId)`. (Phase 5)
            *   Call `twitterInteractionService.postReplyToTweet(tweetUrl, commentText)`. (Phase 6 - Need original tweet URL if possible, otherwise skip/adapt posting).
        *   **Error Handling:** Log errors for specific phases/entries and continue.
        *   **Delay:** Implement configurable delay.
4.  **Completion:** Log agent run completion.

## 4. Project Structure

```
.
‚îú‚îÄ‚îÄ PRD/
‚îÇ   ‚îî‚îÄ‚îÄ SPECIFICATION.md
‚îú‚îÄ‚îÄ scraper_utility/          <-- NEW: Python Scraper
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ scrape_leaderboard.py
‚îú‚îÄ‚îÄ src/                      <-- Node.js Dubbing Agent
‚îÇ   ‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ TwitterSpaceDubbingAgent.ts
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ twitterInteractionService.ts 
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ audioService.ts           
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ speechlabApiService.ts      
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ s3HostingService.ts       
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ types/
‚îÇ   ‚îî‚îÄ‚îÄ main.ts
‚îú‚îÄ‚îÄ tests/
‚îú‚îÄ‚îÄ leaderboard_data.json     <-- Generated by Python utility
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ package.json
‚îî‚îÄ‚îÄ tsconfig.json
```

## 5. Open Questions Addressed

*   Source Language: `en`
*   Audio Hosting: AWS S3, bucket `speechlab-test-files-public`, using env credentials.
*   Sharing Link API: `POST /v1/collaborations/generateSharingLink`, link is in `link` field.
*   Twitter Interaction: Browser automation (`Puppeteer`/`Playwright`).
*   Logging: Detailed, structured, with icons.
*   Test Case: Mario Nawfal tweet specified.
*   Initial Scope: One profile, latest space, sequential processing.
*   Voice Matching: `source`. 